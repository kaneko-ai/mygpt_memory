import streamlit as st
from langchain.vectorstores import Chroma
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI  # ã¾ãŸã¯ HuggingFaceHubï¼ˆç„¡æ–™APIã‚ã‚Šï¼‰

st.title("ğŸ§  è¨˜æ†¶ä»˜ãMyGPTãƒãƒ£ãƒƒãƒˆ")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
query = st.text_input("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# è¨˜æ†¶ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿
embeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
db = Chroma(persist_directory="chroma", embedding_function=embeddings)

# ç°¡æ˜“QAãƒã‚§ãƒ¼ãƒ³
qa = RetrievalQA.from_chain_type(
    llm=OpenAI(temperature=0.3),  # ğŸ” APIã‚­ãƒ¼ä¸è¦ã®æ–¹æ³•ã«å¾Œã§å¤‰æ›´å¯èƒ½
    retriever=db.as_retriever()
)

# å®Ÿè¡Œã¨è¡¨ç¤º
if query:
    answer = qa.run(query)
    st.markdown("### ğŸ§  å›ç­”")
    st.write(answer)
